{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1220c416",
   "metadata": {},
   "source": [
    "<p>Foi pedido para você montar uma arquitetura de um projeto novo da área. Este projeto consiste na transcrição de fala presente em arquivos de áudios e vídeos para finalidades de acessibilidade do consumo de tais mídias. Para torná-lo possível, é necessário pensar, inicialmente, na extração desses arquivos de fontes diversas, depois, não necessariamente nessa ordem (fica a seu critério), nas etapas de armazenamento, etapas de tratamento, etapas de transcrição e, por fim, na disponibilização da informação transcrita para o usuário final.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49535697",
   "metadata": {},
   "source": [
    "<p>As fontes de dados que alimentarão a pipeline serão de produtores de mídia diversos que divulgarão seus arquivos em seus próprios servidores, os quais você terá acesso para realizar a transferência desses arquivos.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d766c3",
   "metadata": {},
   "source": [
    "<p>Desenhe a arquitetura com os passos indicados (e outros que enxergar conveniente) e responda as seguintes perguntas acerca do desenho.\n",
    "<br>\n",
    "<br>\n",
    "<b>1. O processo realizado foi Streaming ou Batch? Explique a escolha.</b>\n",
    "<br>\n",
    "<i>Na escolha de se Streaming ou Batch depende da necessidade de consulta de dados do projeto. Se for necessário consulta em tempo real, ou processar os dados imediatamente após recebidos então a escolha é de Streaming, se não é uma exigência que se tenha os dados imediatamente pode ser feito em lotes (por exemplo a cada 10 arquivos recebidos ou 1 vez por dia / por semana), ou seja via Batch.</i>\n",
    "<br>\n",
    "<b>2. Você utilizou algum Data Warehouse ou Data Lake para armazenamento? Justifique cada uso.</b>\n",
    "<br>\n",
    "<i>Em um mundo ideal, é importante ter uma fonte única de dados, onde se pode manter um registro histórico, confiável e disponível. E neste caso em especial, em se tratando de arquivos não estruturados como áudios e vídeos, de início não seria necessário um DW.</i>\n",
    "<br>\n",
    "<b>3. O processo é ETL ou ELT? Justifique.</b>\n",
    "<br>\n",
    "<i>O processo de ELT normalmente acompanha o Data Lake, pois este é organizado em camadas, cada uma com um objetivo de análise. Um cientista de dados pode precisar dos dados brutos sem tratamentos. Um analista de negócios pode precisar de um DW. Além disso é muito oneroso todo processamento executado.</i>\n",
    "<br>\n",
    "<b>4. Identifique na sua arquitetura onde usaria containers e justifique a importância deles dentro do projeto.</b>\n",
    "<br>\n",
    "<i>Pessoalmente, eu nunca utilizei Docker nem precisei criar um container. Então vou utilizar essa pergunta para aprender um pouco sobre o assunto. Referência o Ramon, um brother engenheiro de dados que me explicou um pouco sobre utilização de containers: \"um contâiner roda os códigos de python ou spark, o objetivo é deixar ambiente de execução pronto para rodar o código em questão, de modo que estejam nele instaladas bibliotecas utilizadas e configurações de ambiente. De início se cria uma imagem baseada no arquivo docker file, e em seguida o container, que é a execução dessa imagem (o código rodando dentro de um ambiente pronto)\"</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1e5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
